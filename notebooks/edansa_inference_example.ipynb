{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# EDANSA Inference Example\n",
                "\n",
                "This notebook demonstrates how to set up the EDANSA environment, download the pre-trained model and sample audio data, and run inference on a sample audio file using `inference.py`."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup Environment\n",
                "\n",
                "First, we clone the repository, install necessary dependencies including the `edansa` package itself, and ensure `ffmpeg` is available for audio processing."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Clone the repository\n",
                "# Make sure you are in the desired parent directory before running this\n",
                "!git clone https://github.com/speechLabBcCuny/EDANSA.git\n",
                "# change this if not running from Google Colab \n",
                "%cd /content/EDANSA\n",
                "\n",
                "# Install the edansa package and dependencies\n",
                "# This installs the package in editable mode, along with requirements\n",
                "!pip install -q -e .\n",
                "\n",
                "# Install ffmpeg (required audio loading backend for torchaudio)\n",
                "# Use sudo for Colab environment, adjust if running locally\n",
                "!sudo apt-get update && sudo apt-get install -y -qq ffmpeg"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Download and Prepare Input Data\n",
                "\n",
                "The main EDANSA repository does not include large audio files. We need to download some test audio assets separately.\n",
                "\n",
                "We will download the `edansa-test-assets-pack-v1.zip` file, which contains the same assets as `src/edansa/tests/assets/` in the repository. We will then unzip it and create an input list file pointing to one of the audio samples within the pack.\n",
                "\n",
                "**Note:** The inference script requires *absolute* paths for the files listed in the input list, especially when run in environments like Colab."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "\n",
                "# Define URL and local paths\n",
                "ASSET_URL = 'https://github.com/speechLabBcCuny/EDANSA/releases/download/dev-test-data-v1.0/edansa-test-assets-pack-v1.zip'\n",
                "ZIP_FILE = 'edansa-test-assets-pack-v1.zip'\n",
                "DOWNLOAD_DEST_DIR = '/content' # Location to download zip in Colab\n",
                "EXTRACT_TARGET_DIR = os.path.join(DOWNLOAD_DEST_DIR, 'downloaded_assets') # Location to unzip assets\n",
                "\n",
                "# Download the assets\n",
                "print(f'Downloading {ASSET_URL}...')\n",
                "!wget -q -O {os.path.join(DOWNLOAD_DEST_DIR, ZIP_FILE)} {ASSET_URL}\n",
                "\n",
                "# Unzip the assets into the target directory\n",
                "print(f'Unzipping {ZIP_FILE} into {EXTRACT_TARGET_DIR}...')\n",
                "os.makedirs(EXTRACT_TARGET_DIR, exist_ok=True)\n",
                "!unzip -q -o {os.path.join(DOWNLOAD_DEST_DIR, ZIP_FILE)} -d {EXTRACT_TARGET_DIR}\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Run Inference\n",
                "\n",
                "Now we execute the `inference.py` script using the main pre-trained model (`31m2plxv-V1`) included in the repository's `assets` directory. We need to provide:\n",
                "*   `--model_path`: Path to the specific model checkpoint file (`.pt`).\n",
                "*   `--config_file`: Path to the model's configuration file (`.json`).\n",
                "*   `--input_folder`: Path to the folder with audio files.\n",
                "*   `--output_folder`: Directory where the prediction CSVs will be saved."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "# Construct and run the inference command\n",
                "print('\\nRunning inference...')\n",
                "!python runs/augment/inference.py \\\n",
                "    --model_path 'assets/31m2plxv-V1/model_info/best_model_370_val_f1_min=0.8028.pt' \\\n",
                "    --config_file 'assets/31m2plxv-V1/model_info/model_config.json' \\\n",
                "    --input_folder '/content/downloaded_assets/audio/real/' \\\n",
                "    --output_folder '/content/edansa_output' \\\n",
                "    --device cpu # Force CPU for potentially limited Colab GPU resources/setup"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Check Results\n",
                "\n",
                "The script saves predictions in the specified output folder. It determines a common 'root' directory from the paths in the input list (here, likely `/content/downloaded_assets/`) and replicates the file's relative path structure under the output folder.\n",
                "\n",
                "Let's list the contents of the output directory and view the generated CSV file."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "\n",
                "# Define where the output is expected and where assets were extracted\n",
                "OUTPUT_DIR = '/content/edansa_output'  # Must match the --output_folder used above\n",
                "\n",
                "example_output_csv = '/content/edansa_output/dalton/04/2023/S4A10291_20230606_025958.csv'\n",
                "print(f'\\nAttempting to read: {example_output_csv}')\n",
                "\n",
                "# Display the first few rows of the output CSV using pandas\n",
                "df = pd.read_csv(example_output_csv)\n",
                "print('\\nPrediction CSV Head:')\n",
                "print(df.head())\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Display files with errors\n",
                "errors_file = '/content/edansa_output/failed_files.csv'\n",
                "df = pd.read_csv(errors_file)\n",
                "# print('\\Errors CSV Head:')\n",
                "print(df.head())"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.x"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
