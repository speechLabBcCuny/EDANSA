{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# EDANSA Inference Example\n",
                "\n",
                "This notebook demonstrates how to set up the EDANSA environment, download the pre-trained model and sample audio data, and run inference on a sample audio file using `inference.py`."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup Environment\n",
                "\n",
                "First, we clone the repository, install necessary dependencies including the `edansa` package itself, and ensure `ffmpeg` is available for audio processing."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Clone the repository\n",
                "# Make sure you are in the desired parent directory before running this\n",
                "!git clone https://github.com/speechLabBcCuny/EDANSA.git\n",
                "%cd EDANSA\n",
                "\n",
                "# Install the edansa package and dependencies\n",
                "# This installs the package in editable mode, along with requirements\n",
                "!pip install -q -e .\n",
                "\n",
                "# Install ffmpeg (required audio loading backend for torchaudio)\n",
                "# Use sudo for Colab environment, adjust if running locally\n",
                "!sudo apt-get update && sudo apt-get install -y -qq ffmpeg"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Download and Prepare Input Data\n",
                "\n",
                "The main EDANSA repository does not include large audio files. We need to download some test audio assets separately.\n",
                "\n",
                "We will download the `edansa-test-assets-pack-v1.zip` file, which contains the same assets as `src/edansa/tests/assets/` in the repository. We will then unzip it and create an input list file pointing to one of the audio samples within the pack.\n",
                "\n",
                "**Note:** The inference script requires *absolute* paths for the files listed in the input list, especially when run in environments like Colab."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "\n",
                "# Define URL and local paths\n",
                "ASSET_URL = 'https://github.com/speechLabBcCuny/EDANSA/releases/download/dev-test-data-v1.0/edansa-test-assets-pack-v1.zip'\n",
                "ZIP_FILE = 'edansa-test-assets-pack-v1.zip'\n",
                "DOWNLOAD_DEST_DIR = '/content' # Location to download zip in Colab\n",
                "EXTRACT_TARGET_DIR = os.path.join(DOWNLOAD_DEST_DIR, 'downloaded_assets') # Location to unzip assets\n",
                "\n",
                "# Download the assets\n",
                "print(f'Downloading {ASSET_URL}...')\n",
                "!wget -q -O {os.path.join(DOWNLOAD_DEST_DIR, ZIP_FILE)} {ASSET_URL}\n",
                "\n",
                "# Unzip the assets into the target directory\n",
                "print(f'Unzipping {ZIP_FILE} into {EXTRACT_TARGET_DIR}...')\n",
                "os.makedirs(EXTRACT_TARGET_DIR, exist_ok=True)\n",
                "!unzip -q -o {os.path.join(DOWNLOAD_DEST_DIR, ZIP_FILE)} -d {EXTRACT_TARGET_DIR}\n",
                "\n",
                "# Define the path to the sample audio file WITHIN the unzipped assets\n",
                "# Based on user feedback, the structure inside EXTRACT_TARGET_DIR is likely 'audio/...', '31m2plxv-V1/...', etc.\n",
                "sample_audio_relative_in_assets = 'audio/real/anwr/47/2022/S4A10341_20220802_235902.flac'\n",
                "sample_audio_absolute = os.path.join(EXTRACT_TARGET_DIR, sample_audio_relative_in_assets)\n",
                "\n",
                "# Verify the sample file exists\n",
                "if not os.path.exists(sample_audio_absolute):\n",
                "    print(f'ERROR: Sample audio file not found at {sample_audio_absolute}')\n",
                "    # You might want to list the contents of the unzipped directory to debug\n",
                "    print(f'Listing contents of {EXTRACT_TARGET_DIR}:')\n",
                "    !ls -R {EXTRACT_TARGET_DIR}\n",
                "else:\n",
                "    print(f'Found sample audio file: {sample_audio_absolute}')\n",
                "\n",
                "# Create a directory for the input list (if it doesn't exist)\n",
                "input_list_dir = os.path.join(DOWNLOAD_DEST_DIR, 'input_lists')\n",
                "os.makedirs(input_list_dir, exist_ok=True)\n",
                "\n",
                "# Define the path for the input file list\n",
                "input_list_file = os.path.join(input_list_dir, 'sample_files.txt')\n",
                "\n",
                "# Write the absolute path to the list file\n",
                "with open(input_list_file, 'w') as f:\n",
                "    f.write(f'{sample_audio_absolute}\\n')\n",
                "\n",
                "# Print the contents of the list file to verify\n",
                "print(f'Created input list file at: {input_list_file}')\n",
                "!cat {input_list_file}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Run Inference\n",
                "\n",
                "Now we execute the `inference.py` script using the main pre-trained model (`31m2plxv-V1`) included in the repository's `assets` directory. We need to provide:\n",
                "*   `--model_path`: Path to the specific model checkpoint file (`.pt`).\n",
                "*   `--config_file`: Path to the model's configuration file (`.json`).\n",
                "*   `--input_files_list`: Path to the text file containing the list of audio files (created above).\n",
                "*   `--output_folder`: Directory where the prediction CSVs will be saved."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "\n",
                "# Define paths relative to the repository root (/content/EDANSA)\n",
                "# Note: We are running this from the '/content/EDANSA' directory (see %cd in first cell)\n",
                "MODEL_PT_PATH = 'assets/31m2plxv-V1/model_info/best_model_370_val_f1_min=0.8028.pt'\n",
                "CONFIG_JSON_PATH = 'assets/31m2plxv-V1/model_info/model_config.json'\n",
                "INPUT_LIST = '/content/input_lists/sample_files.txt' # Absolute path created above\n",
                "OUTPUT_DIR = '/content/edansa_output' # Define an output directory in Colab\n",
                "SCRIPT_PATH = 'runs/augment/inference.py' # Relative path to the script\n",
                "\n",
                "# Verify model and config files exist in the cloned repo\n",
                "if not os.path.exists(MODEL_PT_PATH):\n",
                "    print(f'ERROR: Model file not found at {MODEL_PT_PATH}')\n",
                "if not os.path.exists(CONFIG_JSON_PATH):\n",
                "    print(f'ERROR: Config file not found at {CONFIG_JSON_PATH}')\n",
                "\n",
                "# Create the output directory\n",
                "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
                "\n",
                "# Construct and run the inference command\n",
                "print('\\nRunning inference...')\n",
                "!python {SCRIPT_PATH} \\\n",
                "    --model_path {MODEL_PT_PATH} \\\n",
                "    --config_file {CONFIG_JSON_PATH} \\\n",
                "    --input_files_list {INPUT_LIST} \\\n",
                "    --output_folder {OUTPUT_DIR} \\\n",
                "    --device cpu # Force CPU for potentially limited Colab GPU resources/setup"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Check Results\n",
                "\n",
                "The script saves predictions in the specified output folder. It determines a common 'root' directory from the paths in the input list (here, likely `/content/downloaded_assets/`) and replicates the file's relative path structure under the output folder.\n",
                "\n",
                "Let's list the contents of the output directory and view the generated CSV file."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import os\n",
                "\n",
                "# Define where the output is expected and where assets were extracted\n",
                "OUTPUT_DIR = '/content/edansa_output' # Must match the --output_folder used above\n",
                "EXTRACT_TARGET_DIR = '/content/downloaded_assets' # Where we unzipped the assets\n",
                "\n",
                "# List the output directory contents recursively to see the structure\n",
                "print(f'Contents of {OUTPUT_DIR}:')\n",
                "!ls -R {OUTPUT_DIR}\n",
                "\n",
                "# Construct the expected output path\n",
                "# Input file was: /content/downloaded_assets/audio/real/anwr/47/2022/S4A10341_20220802_235902.flac\n",
                "# Common root identified by script is likely: /content/downloaded_assets/\n",
                "# Relative path should be: audio/real/anwr/47/2022/S4A10341_20220802_235902.flac\n",
                "input_file_absolute = '/content/downloaded_assets/audio/real/anwr/47/2022/S4A10341_20220802_235902.flac'\n",
                "assumed_root_for_output = EXTRACT_TARGET_DIR\n",
                "\n",
                "# Calculate relative path based on the assumed root\n",
                "relative_path = os.path.relpath(input_file_absolute, assumed_root_for_output)\n",
                "output_filename_base = os.path.splitext(relative_path)[0] # Get path without original extension\n",
                "expected_output_csv = os.path.join(OUTPUT_DIR, output_filename_base + '.csv') # Add .csv extension\n",
                "\n",
                "print(f'\\nAttempting to read: {expected_output_csv}')\n",
                "\n",
                "# Display the first few rows of the output CSV using pandas\n",
                "try:\n",
                "    df = pd.read_csv(expected_output_csv)\n",
                "    print('\\nPrediction CSV Head:')\n",
                "    print(df.head())\n",
                "except FileNotFoundError:\n",
                "    print(f'\\nError: Output CSV not found at {expected_output_csv}')\n",
                "    print('Please check the `ls -R` output above and the inference script logs.')\n",
                "    print('Possible issues: Inference script failed, or the output path structure calculation is different than expected.')\n",
                "    # Manually check the expected path based on the ls -R output if needed\n",
                "    # e.g., print('/content/edansa_output/audio/real/anwr/47/2022/S4A10341_20220802_235902.csv')\n",
                "except Exception as e:\n",
                "    print(f'\\nAn error occurred while reading the CSV: {e}')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.x"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
